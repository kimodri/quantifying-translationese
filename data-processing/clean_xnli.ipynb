{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2250b1f0",
   "metadata": {},
   "source": [
    "# Clean XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64fe763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_xnli = pd.read_csv(\"../datasets/raw/xnli.dev.tsv\", sep=\"\\t\")\n",
    "df_xnli = df_xnli[df_xnli[\"language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b68663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli = df_xnli[[\"gold_label\", \"sentence1\", \"sentence2\"]]\n",
    "df_xnli[\"sentence1_len\"] = df_xnli[\"sentence1\"].apply(lambda x: len(x))\n",
    "df_xnli[\"sentence2_len\"] = df_xnli[\"sentence2\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569efdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_label       2490\n",
      "sentence1        2490\n",
      "sentence2        2490\n",
      "sentence1_len    2490\n",
      "sentence2_len    2490\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence1_len</th>\n",
       "      <th>sentence2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>neutral</td>\n",
       "      <td>And he said, Mama, I'm home.</td>\n",
       "      <td>He called his mom as soon as the school bus dr...</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>And he said, Mama, I'm home.</td>\n",
       "      <td>He didn't say a word.</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>entailment</td>\n",
       "      <td>And he said, Mama, I'm home.</td>\n",
       "      <td>He told his mom he had gotten home.</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>neutral</td>\n",
       "      <td>I didn't know what I was going for or anything...</td>\n",
       "      <td>I have never been to Washington so when I was ...</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>I didn't know what I was going for or anything...</td>\n",
       "      <td>I knew exactly what I needed to do as I marche...</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gold_label                                          sentence1  \\\n",
       "9960        neutral                       And he said, Mama, I'm home.   \n",
       "9961  contradiction                       And he said, Mama, I'm home.   \n",
       "9962     entailment                       And he said, Mama, I'm home.   \n",
       "9963        neutral  I didn't know what I was going for or anything...   \n",
       "9964  contradiction  I didn't know what I was going for or anything...   \n",
       "\n",
       "                                              sentence2  sentence1_len  \\\n",
       "9960  He called his mom as soon as the school bus dr...             28   \n",
       "9961                              He didn't say a word.             28   \n",
       "9962                He told his mom he had gotten home.             28   \n",
       "9963  I have never been to Washington so when I was ...            101   \n",
       "9964  I knew exactly what I needed to do as I marche...            101   \n",
       "\n",
       "      sentence2_len  \n",
       "9960             60  \n",
       "9961             21  \n",
       "9962             35  \n",
       "9963             97  \n",
       "9964             62  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_xnli.count())\n",
    "df_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8756749",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filter_xnli = (\n",
    "    ((df_xnli['sentence1_len'] > 20) & (df_xnli['sentence1_len'] < 2000)) & \n",
    "    ((df_xnli['sentence2_len'] > 20) & (df_xnli['sentence2_len'] < 2000))\n",
    ")\n",
    "\n",
    "df_xnli = df_xnli[first_filter_xnli]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e174f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli_neutral = df_xnli[df_xnli[\"gold_label\"] == \"neutral\"]\n",
    "df_xnli_contradiction = df_xnli[df_xnli[\"gold_label\"] == \"contradiction\"]\n",
    "df_xnli_entailment = df_xnli[df_xnli[\"gold_label\"] == \"entailment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352b771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli_neutral_sample = df_xnli_neutral.sample(200, random_state=42)\n",
    "df_xnli_contradiction_sample = df_xnli_contradiction.sample(200, random_state=42)\n",
    "df_xnli_entailment_sample = df_xnli_entailment.sample(200, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da257f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli_neutral_contradiction = pd.concat([df_xnli_neutral_sample, df_xnli_contradiction_sample], ignore_index=True)\n",
    "df_xnli_neutral_contadiction_entailment = pd.concat([df_xnli_neutral_contradiction, df_xnli_entailment_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5492a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli = df_xnli_neutral_contadiction_entailment.drop(columns=['sentence1_len', 'sentence2_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2346c517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>You may also take advantage of our special 2-y...</td>\n",
       "      <td>It costs $30 only if you join in the next two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Therefore, they persistently create a nonstati...</td>\n",
       "      <td>These hypothetical worlds are used to forecast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Anyhow, so I finished came home at 6:30 today ...</td>\n",
       "      <td>I spent most of the day dealing with a complic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>The law redeems not the individual but the com...</td>\n",
       "      <td>The law will redeem America.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Your resolve delivered me from a horrible dang...</td>\n",
       "      <td>She did not want him to help her, though was g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gold_label                                          sentence1  \\\n",
       "0    neutral  You may also take advantage of our special 2-y...   \n",
       "1    neutral  Therefore, they persistently create a nonstati...   \n",
       "2    neutral  Anyhow, so I finished came home at 6:30 today ...   \n",
       "3    neutral  The law redeems not the individual but the com...   \n",
       "4    neutral  Your resolve delivered me from a horrible dang...   \n",
       "\n",
       "                                           sentence2  \n",
       "0  It costs $30 only if you join in the next two ...  \n",
       "1  These hypothetical worlds are used to forecast...  \n",
       "2  I spent most of the day dealing with a complic...  \n",
       "3                       The law will redeem America.  \n",
       "4  She did not want him to help her, though was g...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41bb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xnli.to_csv(\"../datasets/cleaned/cleaned_xnli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64029caa",
   "metadata": {},
   "source": [
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
